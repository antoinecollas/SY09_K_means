---
title: "Projet"
output: html_notebook
---

Notebook

Question 1:
```{r}
recettes_pays <- read.csv("donnees/recettes-pays.data", header=T, sep=",")
head(recettes_pays)
recettes_pays_quant = recettes_pays[,-1]
#sum(recettes_pays_quant[1,])
#sum(recettes_pays_quant[,1])
```

```{r}
print(nrow(recettes_pays))
print(length(unique(recettes_pays[,1])))
print(ncol(recettes_pays))
print(min(recettes_pays_quant))
print(max(recettes_pays_quant))
print(sum(is.na(recettes_pays_quant)))
boxplot(recettes_pays_quant)
#summary(recettes_pays)
```

```{r}
library(corrplot)
M <- cor(recettes_pays_quant)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method = "color") #trop de variables...
```


Question 2:
```{r}
res <- prcomp(recettes_pays_quant)
summary_ACP = summary(res)
print(summary_ACP)
png(filename="imgs/acp.png")
barplot(summary_ACP$importance[2,], las=2)
title(main='Pourcentages d\'inertie expliquée par chaque axe de l\'ACP \n par ordre décroissant.', ylab='pourcentage d\'inertie expliquée')
#(res$sdev)^2 # Les valeurs propres
#res$loadings # Les vecteurs propres
#res$scores # Le nouveau tableau individus-variables
```

Plan 1,2:
```{r}
#ACP_res = data.frame(recettes_pays$origin, res$x, row.names = rownames(recettes_pays))
ACP_res = data.frame(res$x, row.names = rownames(recettes_pays_quant))

png(filename="imgs/acp_plan_1_2.png")
plot(ACP_res[,c(1,2)], type='n', asp=1) # Plan 1,2
text(ACP_res[,1], ACP_res[,2], labels=recettes_pays$origin)
```

Cercle des corrélations pour le plan 1,2:
```{r}
n=dim(recettes_pays_quant)[1]
matrix_recettes_pays_quant <- as.matrix(recettes_pays_quant)
matrix_recettes_pays_quant_centre <- scale(x = matrix_recettes_pays_quant, center = TRUE, scale = FALSE)
V <- (1/n)*t(matrix_recettes_pays_quant_centre) %*% matrix_recettes_pays_quant_centre
tmp <- eigen(V, symmetric=TRUE)
L <- diag(tmp$values)[c(1:n),c(1:n)] #on retire les valeurs propres nulles
print(dim(ACP_res))
correlations <- (1/n) * (t(matrix_recettes_pays_quant_centre)%*%as.matrix(ACP_res)) / (sqrt(diag(V))%*%t(sqrt(diag(L))))
#print(correlations)
print(t(correlations[1,])%*%correlations[1,]) #vérification
print(t(correlations[3,])%*%correlations[3,]) #vérification
corr_1_2 <- correlations[,c(1,2)]
corr_1_3 <- correlations[,c(1,3)]
corr_2_3 <- correlations[,c(2,3)]
```


```{r}
png(filename="imgs/cercle_plan_1_2.png")
plot(corr_1_2, xlim=c(-1.1,1.1), ylim=c(-1.1,1.1), asp=1)
text(correlations[,1], correlations[,2], labels=rownames(correlations), pos=2)
require(plotrix)
draw.circle(0, 0, 1, nv = 1000)
```

Plan 1,3:
```{r}
png(filename="imgs/acp_plan_1_3.png")
plot(ACP_res[,c(1,3)], type='n', asp=1) # Plan 1,3
text(ACP_res[,1], ACP_res[,3], labels=recettes_pays$origin)
```

```{r}
png(filename="imgs/cercle_plan_1_3.png")
plot(corr_1_3, xlim=c(-1.1,1.1), ylim=c(-1.1,1.1), asp=1)
text(correlations[,1], correlations[,3], labels=rownames(correlations), pos=2)
require(plotrix)
draw.circle(0, 0, 1, nv = 1000)
```

Plan 2,3:
```{r}
png(filename="imgs/acp_plan_2_3.png")
plot(ACP_res[,c(2,3)], type='n', asp=1) # Plan 2,3
text(ACP_res[,2], ACP_res[,3], labels=recettes_pays$origin)
```

```{r}
png(filename="imgs/cercle_plan_2_3.png")
plot(corr_2_3, xlim=c(-1.1,1.1), ylim=c(-1.1,1.1), asp=1)
text(correlations[,2], correlations[,3], labels=rownames(correlations), pos=2)
require(plotrix)
draw.circle(0, 0, 1, nv = 1000)
```

Question 3:
```{r}
dist_manhattan_recettes = dist(recettes_pays_quant, method="manhattan")
clust = hclust(dist_manhattan_recettes, method="ward.D2")
print(clust)
png(filename="imgs/CAH_dendrogramme.png")
plot(clust, labels = recettes_pays$origin, xlab = "", ylab = "", main = "Dendrogramme de la classification ascendante hiérarchique")
```

Question 4:
recherche d'un bon K
```{r}
min = vector(length = 10)
for (K in 1:10){
  clust = kmeans(recettes_pays_quant, K)
  #print("K:")
  #print(K)
  temp = clust$tot.withinss
  for (N in 2:100){
    clust = kmeans(recettes_pays_quant, K)
    #print(clust$tot.withinss)
    if (clust$tot.withinss<temp){
      temp = clust$tot.withinss
    }
  }
  min[K]=temp
}
print(min)
png(filename="imgs/K_means_choix_K.png")
plot(min, ylab="Inertie intraclasse", xlab = "K", main = "Inertie intraclasse en fonction du nombre de classes choisi")
```
```{r}
K=3
clust <- kmeans(recettes_pays_quant, K)
#png(filename="imgs/K_means_choix_K.png")
clusters <- data.frame(recettes_pays$origin, clust$cluster)
clusters <- clusters[order(clusters[,2]),] 
print(clusters)
#print(recettes_pays$origin)
#print(clust$cluster)
#plot(clust, main = "K means")
```

Question 6:
```{r}
recettes_echant <- read.csv("donnees/recettes-echant.data", header=T, sep=",")
print(recettes_echant)
```

```{r}
print(nrow(recettes_echant))
print(length(unique(recettes_echant[,1])))
print(ncol(recettes_echant))
recettes_echant_quant <- recettes_echant[,-1]
print(min(recettes_echant_quant))
print(max(recettes_echant_quant))
print(sum(is.na(recettes_echant_quant)))
boxplot(recettes_echant_quant)
#summary(recettes_pays)
```

Question 7:
Pas sur que ce soit bon...
```{r}
aggr <- by(recettes_echant_quant, INDICES=recettes_echant$origin, FUN=colSums)
ing_origin <- as.data.frame(do.call(cbind,aggr))
ing_origin <- ing_origin[order(row.names(ing_origin)),] 
#verification
#print(sum(ing_origin[1,]))
#print(sum(recettes_echant_quant$basil))
nb_recettes_origine = data.frame(t(summary(recettes_echant$origin)))
nb_recettes_origine <- do.call("rbind", replicate(dim(ing_origin)[1], nb_recettes_origine, simplify = FALSE))
ing_origin <- ing_origin / nb_recettes_origine
print(ing_origin)
```

```{r}
dist_ing_origin = dist(ing_origin)
clust = hclust(dist_ing_origin, method="ward.D2")
png(filename="imgs/CAH_dendrogramme_ingredients.png", res=100, height=1000, width=1000)
plot(clust)
```

Deuxième essai de la question 7:
```{r}
ing_origin <- data.frame(t(recettes_echant[,-1]))
ing_origin <- ing_origin[order(row.names(ing_origin)),] 
print(ing_origin)
```

euclidian est sans doute un mauvais choix car si on a deux vecteurs:
0 0 0 0 0 1 0
0 0 1 0 0 0 0
la distance est sqrt(2) ce qui semble faible alors que les deux ingrédients n'ont jamais été utilisés ensemble. La distance euclidienne dépend de la fréquence d'utilisation de deux ingrédients. Deux ingrédients peu utilisés sont proches au sens euclidien car ils sont peu utilisés alors que ce qu'on cherche est à savoir s'ils sont utilisés conjointement.
```{r}
dist_ing_origin = dist(ing_origin, method = "euclidian")
clust = hclust(dist_ing_origin, method="ward.D2")
png(filename="imgs/CAH_dendrogramme_ingredients_euclidian.png", res=100, height=1000, width=1000)
plot(clust)
```

Distance de Jaccard ne prend en compte que quand il y a au moins un 1 dans l'une des deux valeur de chaque couple.
https://fr.wikipedia.org/wiki/Indice_et_distance_de_Jaccard
```{r}
dist_ing_origin = dist(ing_origin, method = "binary")
clust = hclust(dist_ing_origin, method="ward.D2")
png(filename="imgs/CAH_dendrogramme_ingredients_binary.png", res=100, height=1000, width=1000)
plot(clust)
```


Algorithme des k-means avec distance adaptative
```{r}
X <- read.csv("donnees/Synth1.csv", header=T, row.names=1)
z <- X[,3]
X <- X[,-3]
print(X)
plot(X, col=z)
```

Données d'entrée de l'algorithme

```{r}
source(file = "fonctions/distXY.r")

K_means_distance_adaptative <- function(X, K, rho=rep(1, K), n_iter=100, n_ess=1, epsilon=10**(-5)) {
  X = as.matrix(X)
  if (K > nrow(X)){
    print("Erreur: le nombre de classes doit être inférieur ou égale au nombre d'individus.")
    return()
  }
  if (length(rho) != K){
    print("Erreur: la longueur du vecteur rho est différente de K.")
    return()
  }
    
  for (i in 1:n_ess) {
    #initialisaltion
    n <- nrow(X)
    p <- ncol(X)
    
    range_1_nb_indiv = 1:n
    sample_1_nb_indiv <- sample(range_1_nb_indiv, size=K)
    mu <- as.matrix(X[sample_1_nb_indiv,]) #les mu_1, mu_2, ..., mu_K sont en ligne pour avoir un tableau individus-variables

    V_tilde <- array(0,c(p,p,K))
    for(k in 1:K){
      V_tilde[,,k] = diag(p)
      V_tilde[,,k] = (rho[k]**(-1/p)) * V_tilde[,,k]
    }
    
    i = 0
    delta = epsilon + 1 #pour faire au moins une itération de l'algorithme
    while((delta>epsilon) && (i<n_iter)){
      #nouvelle partition
      #pour chaque point on calcule la distance avec les K centres: matrice n,K
      for (k in 1:K) {
        distances_au_centre_mu_k = distXY(X, mu[k,], V_tilde[,,k])
        if (exists("distances_aux_centres")){
          distances_aux_centres = cbind(distances_aux_centres, distances_au_centre_mu_k)
        }else{
          distances_aux_centres = distances_au_centre_mu_k
        }
      }
      #puis on prend la distance la plus faible (sur chaque ligne de la matrice)
      partition = apply(distances_aux_centres, MARGIN=1, FUN = which.min)

      
      #actualisation des paramètres
      mu_old = mu
      #mu=...
      
      #actualisation des critères de convergence
      delta = 0
      for (k in 1:K) {
        delta = delta + dist(rbind(mu[k,], mu_old[k,]), method = 'euclidian')**2
      }
      i=i+1

      print(delta)
    }
      
  }  
  return()
}
```

```{r}
res <- K_means_distance_adaptative(X, K=3)
```



